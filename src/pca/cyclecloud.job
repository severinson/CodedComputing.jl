#!/bin/sh -l
# Run 
#SBATCH --job-name=pca.jl
#SBATCH --output=pca.out
#SBATCH --nodes=73
#SBATCH --time=600:00
#SBATCH --tasks-per-node=1
#SBATCH --partition=hpc

export JULIA_DEPOT_PATH="/shared/home/azureuser/.julia/"
date
filename=/shared/home/azureuser/CodedComputing/src/pca/pca.jl

# 1000 genomes (entire dataset, fully shuffled)

# 1000 genomes dense equivalent matrix
input_file=/shared/home/azureuser/traces/1000genomes-dense-equiv-matrix/1000genomes-dense-equiv-matrix.h5
output_directory=/shared/home/azureuser/traces/1000genomes-dense-equiv-matrix/hpc/

inputdataset=X
iteratedataset=V0
ncomponents=3
npasses=5

nwait_all=( $(($SLURM_NTASKS - 1)))
nsubpartitions_all=( 1 2 5 10 40 80 120 160 240 320)

stepsize=0.9
for nsubpartitions in "${nsubpartitions_all[@]}"
do
    niterations=$(($npasses * $nsubpartitions))

    # nwait=$(($SLURM_NTASKS - 1))
    # echo "[SAG (--nostale)] nsubpartitions: ${nsubpartitions}, nwait: ${nwait}, niterations: $niterations, stepsize: $stepsize"
    # /opt/amazon/openmpi/bin/mpirun -n "$SLURM_NTASKS" julia --project "${filename}" "${input_file}" "${output_directory}/output $(date).h5" --inputdataset ${inputdataset} --stepsize ${stepsize} --nsubpartitions ${nsubpartitions} --nwait ${nwait} --niterations ${niterations} --ncomponents ${ncomponents} --iteratedataset ${iteratedataset} --saveiterates --variancereduced --nostale
    # echo "[SGD] nsubpartitions: ${nsubpartitions}, nwait: ${nwait}, niterations: $niterations"
    # /opt/amazon/openmpi/bin/mpirun -n "$SLURM_NTASKS" julia --project "${filename}" "${input_file}" "${output_directory}/output $(date).h5" --inputdataset ${inputdataset} --stepsize ${stepsize} --nsubpartitions ${nsubpartitions} --nwait ${nwait} --niterations ${niterations} --ncomponents ${ncomponents} --iteratedataset ${iteratedataset} --saveiterates

    for nwait in "${nwait_all[@]}"
    do
        echo "[DSAG] nsubpartitions: ${nsubpartitions}, nwait: ${nwait}, niterations: $niterations"        
        # --saveiterates 
        mpirun -mca coll ^hcoll julia --project "${filename}" "${input_file}" "${output_directory}/output $(date).h5" --inputdataset ${inputdataset} --stepsize ${stepsize} --nsubpartitions ${nsubpartitions} --nwait ${nwait} --niterations ${niterations} --ncomponents ${ncomponents} --iteratedataset ${iteratedataset} --variancereduced

        # echo "[SGD] nsubpartitions: ${nsubpartitions}, nwait: ${nwait}, niterations: $niterations"
        # /opt/amazon/openmpi/bin/mpirun -n "$SLURM_NTASKS" julia --project "${filename}" "${input_file}" "${output_directory}/output $(date).h5" --iteratedataset ${iteratedataset} --stepsize ${stepsize} --nsubpartitions ${nsubpartitions} --nwait ${nwait} --niterations ${niterations} --ncomponents ${ncomponents} --saveiterates
    done
done

# # GD
# stepsize=1.0
# nsubpartitions=1
# nwait=$(($SLURM_NTASKS - 1))
# niterations=$(($npasses * $nsubpartitions))
# echo "[GD] nsubpartitions: ${nsubpartitions}, nwait: ${nwait}, niterations: $niterations"
# mpirun -n "$SLURM_NTASKS" julia --project "${filename}" "${input_file}" "${output_directory}/output $(date).h5" --inputdataset ${inputdataset} --stepsize ${stepsize} --nsubpartitions ${nsubpartitions} --nwait ${nwait} --niterations ${niterations} --ncomponents ${ncomponents} --iteratedataset ${iteratedataset} --saveiterates

echo "Done"
